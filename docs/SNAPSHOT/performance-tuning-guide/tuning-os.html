
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
    <title>Tuning the Operating System and Platform</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="css/style.css" rel="stylesheet">
    <script src="https://use.fontawesome.com/96c4d89611.js"></script>
  </head>
  <body>
<table id="doc-title" cellspacing="0" cellpadding="0">
  <tr>
  <td align="left" valign="top">
  <b>Tuning the Operating System and Platform</b><br />
  </td>
  </tr>
</table>
<hr />

<table width="90%" id="top-nav" cellspacing="0" cellpadding="0">
	<colgroup>
		<col width="12%"/>
		<col width="12%"/>
		<col width="*"/>
	</colgroup>
	<tr>
		<td align="left">
		<a href="tuning-java.html">
			<span class="vector-font"><i class="fa fa-arrow-circle-left" aria-hidden="true"></i></span>
			<span style="position:relative;top:-2px;">Previous</span>
		</a>
		</td>


		<td align="right">
		<a href="toc.html">
			<span class=" vector-font"><i class="fa fa-list vector-font" aria-hidden="true"></i></span>
			<span style="position:relative;top:-2px;">Contents</span>
		</a>
		</td>
	</tr>
</table>


<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p><a id="GSPTG00007"></a><a id="abeir"></a></p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="tuning-the-operating-system-and-platform">5 Tuning the Operating System and Platform</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This chapter discusses tuning the operating system (OS) for optimum
performance. It discusses the following topics:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="#abeis">Server Scaling</a></p>
</li>
<li>
<p><a href="#gfpzp">Solaris 10 Platform-Specific Tuning Information</a></p>
</li>
<li>
<p><a href="#abeix">Tuning for the Solaris OS</a></p>
</li>
<li>
<p><a href="#abeje">Tuning for Solaris on x86</a></p>
</li>
<li>
<p><a href="#abeji">Tuning for Linux platforms</a></p>
</li>
<li>
<p><a href="#gfpzh">Tuning UltraSPARC CMT-Based Systems</a></p>
</li>
</ul>
</div>
<div class="paragraph">
<p><a id="abeis"></a><a id="GSPTG00074"></a><a id="server-scaling"></a></p>
</div>
<div class="sect2">
<h3 id="_server_scaling">Server Scaling</h3>
<div class="paragraph">
<p>This section provides recommendations for optimal performance scaling
server for the following server subsystems:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="#abeit">Processors</a></p>
</li>
<li>
<p><a href="#abeiu">Memory</a></p>
</li>
<li>
<p><a href="#abeiv">Disk Space</a></p>
</li>
<li>
<p><a href="#abeiw">Networking</a></p>
</li>
<li>
<p><a href="#glglf">UDP Buffer Sizes</a></p>
</li>
</ul>
</div>
<div class="paragraph">
<p><a id="abeit"></a><a id="GSPTG00210"></a><a id="processors"></a></p>
</div>
<div class="sect3">
<h4 id="_processors">Processors</h4>
<div class="paragraph">
<p>The GlassFish Server automatically takes advantage of multiple CPUs. In
general, the effectiveness of multiple CPUs varies with the operating
system and the workload, but more processors will generally improve
dynamic content performance.</p>
</div>
<div class="paragraph">
<p>Static content involves mostly input/output (I/O) rather than CPU
activity. If the server is tuned properly, increasing primary memory
will increase its content caching and thus increase the relative amount
of time it spends in I/O versus CPU activity. Studies have shown that
doubling the number of CPUs increases servlet performance by 50 to 80
percent.</p>
</div>
<div class="paragraph">
<p><a id="abeiu"></a><a id="GSPTG00211"></a><a id="memory"></a></p>
</div>
</div>
<div class="sect3">
<h4 id="_memory">Memory</h4>
<div class="paragraph">
<p>See the section Hardware and Software Requirements in the GlassFish
Server Release Notes for specific memory recommendations for each
supported operating system.</p>
</div>
<div class="paragraph">
<p><a id="abeiv"></a><a id="GSPTG00212"></a><a id="disk-space"></a></p>
</div>
</div>
<div class="sect3">
<h4 id="_disk_space">Disk Space</h4>
<div class="paragraph">
<p>It is best to have enough disk space for the OS, document tree, and log
files. In most cases 2GB total is sufficient.</p>
</div>
<div class="paragraph">
<p>Put the OS, swap/paging file, GlassFish Server logs, and document tree
each on separate hard drives. This way, if the log files fill up the log
drive, the OS does not suffer. Also, its easy to tell if the OS paging
file is causing drive activity, for example.</p>
</div>
<div class="paragraph">
<p>OS vendors generally provide specific recommendations for how much swap
or paging space to allocate. Based on Oracle testing, GlassFish Server
performs best with swap space equal to RAM, plus enough to map the
document tree.</p>
</div>
<div class="paragraph">
<p><a id="abeiw"></a><a id="GSPTG00213"></a><a id="networking"></a></p>
</div>
</div>
<div class="sect3">
<h4 id="_networking">Networking</h4>
<div class="paragraph">
<p>To determine the bandwidth the application needs, determine the
following values:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The number of peak concurrent users (N <sub>peak</sub>) the server needs to
handle.</p>
</li>
<li>
<p>The average request size on your site, r. The average request can
include multiple documents. When in doubt, use the home page and all its
associated files and graphics.</p>
</li>
<li>
<p>Decide how long, t, the average user will be willing to wait for a
document at peak utilization.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Then, the bandwidth required is:</p>
</div>
<div class="paragraph">
<p>N<sub>peak</sub>r / t</p>
</div>
<div class="paragraph">
<p>For example, to support a peak of 50 users with an average document size
of 24 Kbytes, and transferring each document in an average of 5 seconds,
requires 240 Kbytes (1920 Kbit/s). So the site needs two T1 lines (each
1544 Kbit/s). This bandwidth also allows some overhead for growth.</p>
</div>
<div class="paragraph">
<p>The server&#8217;s network interface card must support more than the WAN to
which it is connected. For example, if you have up to three T1 lines,
you can get by with a 10BaseT interface. Up to a T3 line (45 Mbit/s),
you can use 100BaseT. But if you have more than 50 Mbit/s of WAN
bandwidth, consider configuring multiple 100BaseT interfaces, or look at
Gigabit Ethernet technology.</p>
</div>
<div class="paragraph">
<p><a id="glglf"></a><a id="GSPTG00214"></a><a id="udp-buffer-sizes"></a></p>
</div>
</div>
<div class="sect3">
<h4 id="_udp_buffer_sizes">UDP Buffer Sizes</h4>
<div class="paragraph">
<p>GlassFish Server uses User Datagram Protocol (UDP) for the transmission
of multicast messages to GlassFish Server instances in a cluster. For
peak performance from a GlassFish Server cluster that uses UDP
multicast, limit the need to retransmit UDP messages. To limit the need
to retransmit UDP messages, set the size of the UDP buffer to avoid
excessive UDP datagram loss.</p>
</div>
<div class="paragraph">
<p><a id="sthref13"></a><a id="to-determine-an-optimal-udp-buffer-size"></a></p>
</div>
<div class="sect4">
<h5 id="_to_determine_an_optimal_udp_buffer_size">To Determine an Optimal UDP Buffer Size</h5>
<div class="paragraph">
<p>The size of UDP buffer that is required to prevent excessive UDP
datagram loss depends on many factors, such as:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The number of instances in the cluster</p>
</li>
<li>
<p>The number of instances on each host</p>
</li>
<li>
<p>The number of processors</p>
</li>
<li>
<p>The amount of memory</p>
</li>
<li>
<p>The speed of the hard disk for virtual memory</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>If only one instance is running on each host in your cluster, the
default UDP buffer size should suffice. If several instances are running
on each host, determine whether the UDP buffer is large enough by
testing for the loss of UDP packets.</p>
</div>
<table class="tableblock frame-all grid-all spread">
<colgroup>
<col style="width: 100%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><div><div class="paragraph">
<p>Note:</p>
</div>
<div class="paragraph">
<p>On Linux systems, the default UDP buffer size might be insufficient even
if only one instance is running on each host. In this situation, set the
UDP buffer size as explained in <a href="#glglz">To Set the UDP Buffer Size
on Linux Systems</a>.</p>
</div></div></td>
</tr>
</tbody>
</table>
<div id="glgiw" class="olist arabic">
<ol class="arabic">
<li>
<p>Ensure that no GlassFish Server clusters are running.<br>
If necessary, stop any running clusters as explained in
"<a href="../ha-administration-guide/instances.html#GSHAG00110">To Stop a Cluster</a>" in GlassFish Server Open Source
Edition High Availability Administration Guide.</p>
</li>
<li>
<p>Determine the absolute number of lost UDP packets when no clusters
are running.<br>
How you determine the number of lost packets depends on the operating
system. For example:</p>
<div class="ulist">
<ul>
<li>
<p>On Linux systems, use the <code>netstat -su</code> command and look for the
<code>packet receive errors</code> count in the <code>Udp</code> section.</p>
</li>
<li>
<p>On AIX systems, use the <code>netstat -s</code> command and look for the
<code>fragments dropped (dup or out of space)</code> count in the <code>ip</code> section.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Start all the clusters that are configured for your installation of
GlassFish Server.<br>
Start each cluster as explained in "<a href="../ha-administration-guide/instances.html#GSHAG00109">To Start a
Cluster</a>" in GlassFish Server Open Source Edition High Availability
Administration Guide.</p>
</li>
<li>
<p>Determine the absolute number of lost UDP packets after the clusters
are started.</p>
</li>
<li>
<p>If the difference in the number of lost packets is significant,
increase the size of the UDP buffer.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><a id="glglz"></a><a id="GSPTG00040"></a><a id="to-set-the-udp-buffer-size-on-linux-systems"></a></p>
</div>
</div>
<div class="sect4">
<h5 id="_to_set_the_udp_buffer_size_on_linux_systems">To Set the UDP Buffer Size on Linux Systems</h5>
<div class="paragraph">
<p>On Linux systems, a default UDP buffer size is set for the client, but
not for the server. Therefore, on Linux systems, the UDP buffer size
might have to be increased. Setting the UDP buffer size involves setting
the following kernel parameters:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>net.core.rmem_max</code></p>
</li>
<li>
<p><code>net.core.wmem_max</code></p>
</li>
<li>
<p><code>net.core.rmem_default</code></p>
</li>
<li>
<p><code>net.core.wmem_default</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Set the kernel parameters in the <code>/etc/sysctl.conf</code> file or at runtime.</p>
</div>
<div class="paragraph">
<p>If you set the parameters in the <code>/etc/sysctl.conf</code> file, the settings
are preserved when the system is rebooted. If you set the parameters at
runtime, the settings are not preserved when the system is rebooted.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>To set the parameters in the <code>/etc/sysctl.conf</code> file, add or edit the
following lines in the file:<br></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre>net.core.rmem_max=rmem-max
net.core.wmem_max=wmem-max
net.core.rmem_default=rmem-default
net.core.wmem_default=wmem-default</pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>To set the parameters at runtime, use the sysctl command.<br></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre>$ /sbin/sysctl -w net.core.rmem_max=rmem-max \
net.core.wmem_max=wmem-max \
net.core.rmem_default=rmem-default \
net.core.wmem_default=wmem-default</pre>
</div>
</div>
<div id="sthref14" class="paragraph">
<p>Example 5-1 Setting the UDP Buffer Size in the <code>/etc/sysctl.conf</code> File</p>
</div>
<div class="paragraph">
<p>This example shows the lines in the <code>/etc/sysctl.conf</code> file for setting
the kernel parameters for controlling the UDP buffer size to 524288.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">net.core.rmem_max=524288
net.core.wmem_max=524288
net.core.rmem_default=524288
net.core.wmem_default=524288</code></pre>
</div>
</div>
<div class="paragraph">
<p><a id="GSPTG00034"></a><a id="glgjp"></a></p>
</div>
<div class="paragraph">
<p>Example 5-2 Setting the UDP Buffer Size at Runtime</p>
</div>
<div class="paragraph">
<p>This example sets the kernel parameters for controlling the UDP buffer
size to 524288 at runtime.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">$ /sbin/sysctl -w net.core.rmem_max=524288 \
net.core.wmem_max=52428 \
net.core.rmem_default=52428 \
net.core.wmem_default=524288
net.core.rmem_max = 524288
net.core.wmem_max = 52428
net.core.rmem_default = 52428
net.core.wmem_default = 524288</code></pre>
</div>
</div>
<div class="paragraph">
<p><a id="gfpzp"></a><a id="GSPTG00075"></a><a id="solaris-10-platform-specific-tuning-information"></a></p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_solaris_10_platform_specific_tuning_information">Solaris 10 Platform-Specific Tuning Information</h3>
<div class="paragraph">
<p>Solaris Dynamic Tracing (DTrace) is a comprehensive dynamic tracing
framework for the Solaris Operating System (OS). You can use the DTrace
Toolkit to monitor the system. The DTrace Toolkit is available through
the OpenSolaris project from the
<a href="http://hub.opensolaris.org/bin/view/Community+Group+dtrace/dtracetoolkit">DTraceToolkit
page</a>
(<code>http://hub.opensolaris.org/bin/view/Community+Group+dtrace/dtracetoolkit</code>).</p>
</div>
<div class="paragraph">
<p><a id="abeix"></a><a id="GSPTG00076"></a><a id="tuning-for-the-solaris-os"></a></p>
</div>
</div>
<div class="sect2">
<h3 id="_tuning_for_the_solaris_os">Tuning for the Solaris OS</h3>
<div class="ulist">
<ul>
<li>
<p><a href="#abeiy">Tuning Parameters</a></p>
</li>
<li>
<p><a href="#abeja">File Descriptor Setting</a></p>
</li>
</ul>
</div>
<div class="paragraph">
<p><a id="abeiy"></a><a id="GSPTG00215"></a><a id="tuning-parameters"></a></p>
</div>
<div class="sect3">
<h4 id="_tuning_parameters">Tuning Parameters</h4>
<div class="paragraph">
<p>Tuning Solaris TCP/IP settings benefits programs that open and close
many sockets. Since the GlassFish Server operates with a small fixed set
of connections, the performance gain might not be significant.</p>
</div>
<div class="paragraph">
<p>The following table shows Solaris tuning parameters that affect
performance and scalability benchmarking. These values are examples of
how to tune your system for best performance.</p>
</div>
<div class="paragraph">
<p><a id="sthref15"></a><a id="gacmm"></a></p>
</div>
<div class="paragraph">
<p>Table 5-1 Tuning Parameters for Solaris</p>
</div>
<table class="tableblock frame-all grid-all spread">
<colgroup>
<col style="width: 14%;">
<col style="width: 6%;">
<col style="width: 34%;">
<col style="width: 28.9999%;">
<col style="width: 17.0001%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Scope</th>
<th class="tableblock halign-left valign-top">Default</th>
<th class="tableblock halign-left valign-top">Tuned Value</th>
<th class="tableblock halign-left valign-top">Comments</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>rlim_fd_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>/etc/system</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">65536</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">65536</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Limit of process open file
descriptors. Set to account for expected load (for associated sockets,
files, and pipes if any).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>rlim_fd_cur</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>/etc/system</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1024</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8192</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>sq_max_size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>/etc/system</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Controls streams driver queue size;
setting to 0 makes it infinite so the performance runs won&#8217;t be hit by
lack of buffer space. Set on clients too. Note that setting
<code>sq_max_size</code> to 0 might not be optimal for production systems with high
network traffic.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>tcp_close_wait_interval</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ndd /dev/tcp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">240000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">60000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Set on
clients too.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>tcp_time_wait_interval</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ndd /dev/tcp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">240000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">60000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Set on clients
too.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>tcp_conn_req_max_q</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ndd /dev/tcp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">128</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1024</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>tcp_conn_req_max_q0</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ndd /dev/tcp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1024</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4096</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>tcp_ip_abort_interval</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ndd /dev/tcp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">480000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">60000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>tcp_keepalive_interval</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ndd /dev/tcp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">7200000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">900000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">For high
traffic web sites, lower this value.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>tcp_rexmit_interval_initial</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ndd /dev/tcp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If
retransmission is greater than 30-40%, you should increase this value.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>tcp_rexmit_interval_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ndd /dev/tcp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">240000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">10000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>tcp_rexmit_interval_min</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ndd /dev/tcp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">200</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>tcp_smallest_anon_port</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ndd /dev/tcp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32768</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1024</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Set on clients
too.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>tcp_slow_start_initial</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ndd /dev/tcp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Slightly faster
transmission of small amounts of data.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>tcp_xmit_hiwat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ndd /dev/tcp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8129</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32768</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Size of transmit buffer.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>tcp_recv_hiwat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ndd /dev/tcp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8129</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32768</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Size of receive buffer.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>tcp_conn_hash_size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ndd /dev/tcp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">512</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8192</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Size of connection
hash table. See <a href="#abeiz">Sizing the Connection Hash Table</a>.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><a id="abeiz"></a><a id="GSPTG00153"></a><a id="sizing-the-connection-hash-table"></a></p>
</div>
<div class="sect4">
<h5 id="_sizing_the_connection_hash_table">Sizing the Connection Hash Table</h5>
<div class="paragraph">
<p>The connection hash table keeps all the information for active TCP
connections. Use the following command to get the size of the connection
hash table:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">ndd -get /dev/tcp tcp_conn_hash</code></pre>
</div>
</div>
<div class="paragraph">
<p>This value does not limit the number of connections, but it can cause
connection hashing to take longer. The default size is 512.</p>
</div>
<div class="paragraph">
<p>To make lookups more efficient, set the value to half of the number of
concurrent TCP connections that are expected on the server. You can set
this value only in <code>/etc/system</code>, and it becomes effective at boot time.</p>
</div>
<div class="paragraph">
<p>Use the following command to get the current number of TCP connections.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">netstat -nP tcp|wc -l</code></pre>
</div>
</div>
<div class="paragraph">
<p><a id="abeja"></a><a id="GSPTG00216"></a><a id="file-descriptor-setting"></a></p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_file_descriptor_setting">File Descriptor Setting</h4>
<div class="paragraph">
<p>On the Solaris OS, setting the maximum number of open files property
using <code>ulimit</code> has the biggest impact on efforts to support the maximum
number of RMI/IIOP clients.</p>
</div>
<div class="paragraph">
<p>To increase the hard limit, add the following command to <code>/etc/system</code>
and reboot it once:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">set rlim_fd_max = 8192</code></pre>
</div>
</div>
<div class="paragraph">
<p>Verify this hard limit by using the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">ulimit -a -H</code></pre>
</div>
</div>
<div class="paragraph">
<p>Once the above hard limit is set, increase the value of this property
explicitly (up to this limit) using the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">ulimit -n 8192</code></pre>
</div>
</div>
<div class="paragraph">
<p>Verify this limit by using the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">ulimit -a</code></pre>
</div>
</div>
<div class="paragraph">
<p>For example, with the default <code>ulimit</code> of 64, a simple test driver can
support only 25 concurrent clients, but with <code>ulimit</code> set to 8192, the
same test driver can support 120 concurrent clients. The test driver
spawned multiple threads, each of which performed a JNDI lookup and
repeatedly called the same business method with a think (delay) time of
500 ms between business method calls, exchanging data of about 100 KB.
These settings apply to RMI/IIOP clients on the Solaris OS.</p>
</div>
<div class="paragraph">
<p><a id="abeje"></a><a id="GSPTG00077"></a><a id="tuning-for-solaris-on-x86"></a></p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_tuning_for_solaris_on_x86">Tuning for Solaris on x86</h3>
<div class="paragraph">
<p>The following are some options to consider when tuning Solaris on x86
for GlassFish Server:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="#abejg">File Descriptors</a></p>
</li>
<li>
<p><a href="#abejh">IP Stack Settings</a></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Some of the values depend on the system resources available. After
making any changes to <code>/etc/system</code>, reboot the machines.</p>
</div>
<div class="paragraph">
<p><a id="abejg"></a><a id="GSPTG00217"></a><a id="file-descriptors"></a></p>
</div>
<div class="sect3">
<h4 id="_file_descriptors">File Descriptors</h4>
<div class="paragraph">
<p>Add (or edit) the following lines in the <code>/etc/system</code> file:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">set rlim_fd_max=65536
set rlim_fd_cur=65536
set sq_max_size=0
set tcp:tcp_conn_hash_size=8192
set autoup=60
set pcisch:pci_stream_buf_enable=0</code></pre>
</div>
</div>
<div class="paragraph">
<p>These settings affect the file descriptors.</p>
</div>
<div class="paragraph">
<p><a id="abejh"></a><a id="GSPTG00218"></a><a id="ip-stack-settings"></a></p>
</div>
</div>
<div class="sect3">
<h4 id="_ip_stack_settings">IP Stack Settings</h4>
<div class="paragraph">
<p>Add (or edit) the following lines in the <code>/etc/system</code> file:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">set ip:tcp_squeue_wput=1
set ip:tcp_squeue_close=1
set ip:ip_squeue_bind=1
set ip:ip_squeue_worker_wait=10
set ip:ip_squeue_profile=0</code></pre>
</div>
</div>
<div class="paragraph">
<p>These settings tune the IP stack.</p>
</div>
<div class="paragraph">
<p>To preserve the changes to the file between system reboots, place the
following changes to the default TCP variables in a startup script that
gets executed when the system reboots:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">ndd -set /dev/tcp tcp_time_wait_interval 60000
ndd -set /dev/tcp tcp_conn_req_max_q 16384
ndd -set /dev/tcp tcp_conn_req_max_q0 16384
ndd -set /dev/tcp tcp_ip_abort_interval 60000
ndd -set /dev/tcp tcp_keepalive_interval 7200000
ndd -set /dev/tcp tcp_rexmit_interval_initial 4000
ndd -set /dev/tcp tcp_rexmit_interval_min 3000
ndd -set /dev/tcp tcp_rexmit_interval_max 10000
ndd -set /dev/tcp tcp_smallest_anon_port 32768
ndd -set /dev/tcp tcp_slow_start_initial 2
ndd -set /dev/tcp tcp_xmit_hiwat 32768
ndd -set /dev/tcp tcp_recv_hiwat 32768</code></pre>
</div>
</div>
<div class="paragraph">
<p><a id="abeji"></a><a id="GSPTG00078"></a><a id="tuning-for-linux-platforms"></a></p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_tuning_for_linux_platforms">Tuning for Linux platforms</h3>
<div class="paragraph">
<p>To tune for maximum performance on Linux, you need to make adjustments
to the following:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="#gkvjl">Startup Files</a></p>
</li>
<li>
<p><a href="#abejj">File Descriptors</a></p>
</li>
<li>
<p><a href="#abejk">Virtual Memory</a></p>
</li>
<li>
<p><a href="#abejl">Network Interface</a></p>
</li>
<li>
<p><a href="#abejm">Disk I/O Settings</a></p>
</li>
<li>
<p><a href="#abejn">TCP/IP Settings</a></p>
</li>
</ul>
</div>
<div class="paragraph">
<p><a id="gkvjl"></a><a id="GSPTG00219"></a><a id="startup-files"></a></p>
</div>
<div class="sect3">
<h4 id="_startup_files">Startup Files</h4>
<div class="paragraph">
<p>The following parameters must be added to the <code>/etc/rc.d/rc.local</code> file
that gets executed during system startup.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">&lt;-- begin
#max file count updated ~256 descriptors per 4Mb.
Specify number of file descriptors based on the amount of system RAM.
echo "6553"&gt; /proc/sys/fs/file-max
#inode-max 3-4 times the file-max
#file not present!!!!!
#echo"262144"&gt; /proc/sys/fs/inode-max
#make more local ports available
echo 1024 25000&gt; /proc/sys/net/ipv4/ip_local_port_range
#increase the memory available with socket buffers
echo 2621143&gt; /proc/sys/net/core/rmem_max
echo 262143&gt; /proc/sys/net/core/rmem_default
#above configuration for 2.4.X kernels
echo 4096 131072 262143&gt; /proc/sys/net/ipv4/tcp_rmem
echo 4096 13107262143&gt; /proc/sys/net/ipv4/tcp_wmem
#disable "RFC2018 TCP Selective Acknowledgements," and
"RFC1323 TCP timestamps" echo 0&gt; /proc/sys/net/ipv4/tcp_sack
echo 0&gt; /proc/sys/net/ipv4/tcp_timestamps
#double maximum amount of memory allocated to shm at runtime
echo "67108864"&gt; /proc/sys/kernel/shmmax
#improve virtual memory VM subsystem of the Linux
echo "100 1200 128 512 15 5000 500 1884 2"&gt; /proc/sys/vm/bdflush
#we also do a sysctl
sysctl -p /etc/sysctl.conf
-- end --&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>Additionally, create an <code>/etc/sysctl.conf</code> file and append it with the
following values:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">&lt;-- begin
 #Disables packet forwarding
net.ipv4.ip_forward = 0
#Enables source route verification
net.ipv4.conf.default.rp_filter = 1
#Disables the magic-sysrq key
kernel.sysrq = 0
fs.file-max=65536
vm.bdflush = 100 1200 128 512 15 5000 500 1884 2
net.ipv4.ip_local_port_range = 1024 65000
net.core.rmem_max= 262143
net.core.rmem_default = 262143
net.ipv4.tcp_rmem = 4096 131072 262143
net.ipv4.tcp_wmem = 4096 131072 262143
net.ipv4.tcp_sack = 0
net.ipv4.tcp_timestamps = 0
kernel.shmmax = 67108864</code></pre>
</div>
</div>
<div class="paragraph">
<p><a id="abejj"></a><a id="GSPTG00220"></a><a id="file-descriptors-1"></a></p>
</div>
</div>
<div class="sect3">
<h4 id="_file_descriptors_2">File Descriptors</h4>
<div class="paragraph">
<p>You may need to increase the number of file descriptors from the
default. Having a higher number of file descriptors ensures that the
server can open sockets under high load and not abort requests coming in
from clients.</p>
</div>
<div class="paragraph">
<p>Start by checking system limits for file descriptors with this command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">cat /proc/sys/fs/file-max
8192</code></pre>
</div>
</div>
<div class="paragraph">
<p>The current limit shown is 8192. To increase it to 65535, use the
following command (as root):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">echo "65535"&gt; /proc/sys/fs/file-max</code></pre>
</div>
</div>
<div class="paragraph">
<p>To make this value to survive a system reboot, add it to
<code>/etc/sysctl.conf</code> and specify the maximum number of open files
permitted:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">fs.file-max = 65535</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note that the parameter is not <code>proc.sys.fs.file-max</code>, as one might
expect.</p>
</div>
<div class="paragraph">
<p>To list the available parameters that can be modified using <code>sysctl</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">sysctl -a</code></pre>
</div>
</div>
<div class="paragraph">
<p>To load new values from the <code>sysctl.conf</code> file:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">sysctl -p /etc/sysctl.conf</code></pre>
</div>
</div>
<div class="paragraph">
<p>To check and modify limits per shell, use the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">limit</code></pre>
</div>
</div>
<div class="paragraph">
<p>The output will look something like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">cputime         unlimited
filesize        unlimited
datasize        unlimited
stacksize       8192 kbytes
coredumpsize    0 kbytes
memoryuse       unlimited
descriptors     1024
memorylocked    unlimited
maxproc         8146
openfiles       1024</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>openfiles</code> and <code>descriptors</code> show a limit of 1024. To increase the
limit to 65535 for all users, edit <code>/etc/security/limits.conf</code> as root,
and modify or add the <code>nofile</code> setting (number of file) entries:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">*         soft    nofile                     65535
*         hard    nofile                     65535</code></pre>
</div>
</div>
<div class="paragraph">
<p>The character "<code>*</code>" is a wildcard that identifies all users. You could
also specify a user ID instead.</p>
</div>
<div class="paragraph">
<p>Then edit <code>/etc/pam.d/login</code> and add the line:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">session required /lib/security/pam_limits.so</code></pre>
</div>
</div>
<div class="paragraph">
<p>On Red Hat, you also need to edit <code>/etc/pam.d/sshd</code> and add the
following line:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">session required /lib/security/pam_limits.so</code></pre>
</div>
</div>
<div class="paragraph">
<p>On many systems, this procedure will be sufficient. Log in as a regular
user and try it before doing the remaining steps. The remaining steps
might not be required, depending on how pluggable authentication modules
(PAM) and secure shell (SSH) are configured.</p>
</div>
<div class="paragraph">
<p><a id="abejk"></a><a id="GSPTG00221"></a><a id="virtual-memory"></a></p>
</div>
</div>
<div class="sect3">
<h4 id="_virtual_memory">Virtual Memory</h4>
<div class="paragraph">
<p>To change virtual memory settings, add the following to <code>/etc/rc.local</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">echo 100 1200 128 512 15 5000 500 1884 2&gt; /proc/sys/vm/bdflush</code></pre>
</div>
</div>
<div class="paragraph">
<p>For more information, view the man pages for <code>bdflush</code>.</p>
</div>
<div class="paragraph">
<p><a id="abejl"></a><a id="GSPTG00222"></a><a id="network-interface"></a></p>
</div>
</div>
<div class="sect3">
<h4 id="_network_interface">Network Interface</h4>
<div class="paragraph">
<p>To ensure that the network interface is operating in full duplex mode,
add the following entry into <code>/etc/rc.local</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">mii-tool -F 100baseTx-FD eth0</code></pre>
</div>
</div>
<div class="paragraph">
<p>where eth0 is the name of the network interface card (NIC).</p>
</div>
<div class="paragraph">
<p><a id="abejm"></a><a id="GSPTG00223"></a><a id="disk-io-settings"></a></p>
</div>
</div>
<div class="sect3">
<h4 id="_disk_i_o_settings">Disk I/O Settings</h4>
<div class="literalblock">
<div class="content">
<pre> </pre>
</div>
</div>
<div class="paragraph">
<p><a id="gaclw"></a><a id="GSPTG00041"></a><a id="to-tune-disk-io-performance-for-non-scsi-disks"></a></p>
</div>
<div class="sect4">
<h5 id="_to_tune_disk_i_o_performance_for_non_scsi_disks">To tune disk I/O performance for non SCSI disks</h5>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Test the disk speed.<br>
Use this command:<br></p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre>/sbin/hdparm -t /dev/hdX</pre>
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Enable direct memory access (DMA).<br>
Use this command:<br></p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre>/sbin/hdparm -d1 /dev/hdX</pre>
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Check the speed again using the <code>hdparm</code> command.<br>
Given that DMA is not enabled by default, the transfer rate might have
improved considerably. In order to do this at every reboot, add the
<code>/sbin/hdparm -d1 /dev/hdX</code> line to <code>/etc/conf.d/local.start</code>,
<code>/etc/init.d/rc.local</code>, or whatever the startup script is called.<br>
For information on SCSI disks, see:
<a href="http://people.redhat.com/alikins/system_tuning.html#scsi">System Tuning
for Linux Servers — SCSI</a>
(<code>http://people.redhat.com/alikins/system_tuning.html#scsi</code>).</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><a id="abejn"></a><a id="GSPTG00224"></a><a id="tcpip-settings"></a></p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_tcp_ip_settings">TCP/IP Settings</h4>
<div class="literalblock">
<div class="content">
<pre> </pre>
</div>
</div>
<div class="paragraph">
<p><a id="gacmd"></a><a id="GSPTG00042"></a><a id="to-tune-the-tcpip-settings"></a></p>
</div>
<div class="sect4">
<h5 id="_to_tune_the_tcp_ip_settings">To tune the TCP/IP settings</h5>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Add the following entry to <code>/etc/rc.local</code><br></p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre>echo 30&gt; /proc/sys/net/ipv4/tcp_fin_timeout
echo 60000&gt; /proc/sys/net/ipv4/tcp_keepalive_time
echo 15000&gt; /proc/sys/net/ipv4/tcp_keepalive_intvl
echo 0&gt; /proc/sys/net/ipv4/tcp_window_scaling</pre>
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Add the following to <code>/etc/sysctl.conf</code><br></p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre># Disables packet forwarding
net.ipv4.ip_forward = 0
# Enables source route verification
net.ipv4.conf.default.rp_filter = 1
# Disables the magic-sysrq key
kernel.sysrq = 0
net.ipv4.ip_local_port_range = 1204 65000
net.core.rmem_max = 262140
net.core.rmem_default = 262140
net.ipv4.tcp_rmem = 4096 131072 262140
net.ipv4.tcp_wmem = 4096 131072 262140
net.ipv4.tcp_sack = 0
net.ipv4.tcp_timestamps = 0
net.ipv4.tcp_window_scaling = 0
net.ipv4.tcp_keepalive_time = 60000
net.ipv4.tcp_keepalive_intvl = 15000
net.ipv4.tcp_fin_timeout = 30</pre>
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Add the following as the last entry in <code>/etc/rc.local</code><br></p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre>sysctl -p /etc/sysctl.conf</pre>
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Reboot the system.</p>
</li>
<li>
<p>Use this command to increase the size of the transmit buffer:<br></p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre>tcp_recv_hiwat ndd /dev/tcp 8129 32768</pre>
</div>
</div>
<div class="paragraph">
<p><a id="gfpzh"></a><a id="GSPTG00079"></a><a id="tuning-ultrasparc-cmt-based-systems"></a></p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_tuning_ultrasparc_cmt_based_systems">Tuning UltraSPARC CMT-Based Systems</h3>
<div class="paragraph">
<p>Use a combination of tunable parameters and other parameters to tune
UltraSPARC CMT-based systems. These values are an example of how you
might tune your system to achieve the desired result.</p>
</div>
<div class="paragraph">
<p><a id="gfpzv"></a><a id="GSPTG00225"></a><a id="tuning-operating-system-and-tcp-settings"></a></p>
</div>
<div class="sect3">
<h4 id="_tuning_operating_system_and_tcp_settings">Tuning Operating System and TCP Settings</h4>
<div class="paragraph">
<p>The following table shows the operating system tuning for Solaris 10
used when benchmarking for performance and scalability on UtraSPARC
CMT-based systems (64-bit systems).</p>
</div>
<div class="paragraph">
<p><a id="sthref16"></a><a id="gkuaa"></a></p>
</div>
<div class="paragraph">
<p>Table 5-2 Tuning 64-bit Systems for Performance Benchmarking</p>
</div>
<table class="tableblock frame-all grid-all spread">
<colgroup>
<col style="width: 14%;">
<col style="width: 6%;">
<col style="width: 32%;">
<col style="width: 32%;">
<col style="width: 16%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Scope</th>
<th class="tableblock halign-left valign-top">Default Value</th>
<th class="tableblock halign-left valign-top">Tuned Value</th>
<th class="tableblock halign-left valign-top">Comments</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>rlim_fd_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>/etc/system</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">65536</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">260000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Process open file
descriptors limit; should account for the expected load (for the
associated sockets, files, pipes if any).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>hires_tick</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>/etc/system</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>sq_max_size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>/etc/system</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Controls streams driver queue size;
setting to 0 makes it infinite so the performance runs won&#8217;t be hit by
lack of buffer space. Set on clients too. Note that setting
<code>sq_max_size</code> to 0 might not be optimal for production systems with high
network traffic.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ip:ip_squeue_bind</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ip:ip_squeue_fanout</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ipge:ipge_taskq_disable</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>/etc/system</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ipge:ipge_tx_ring_size</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>/etc/system</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2048</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ipge:ipge_srv_fifo_depth</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>/etc/system</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2048</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ipge:ipge_bcopy_thresh</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>/etc/system</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">384</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ipge:ipge_dvma_thresh</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>/etc/system</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">384</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ipge:ipge_tx_syncq</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>/etc/system</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>tcp_conn_req_max_q</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ndd /dev/tcp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">128</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>tcp_conn_req_max_q0</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ndd /dev/tcp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1024</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>tcp_max_buf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ndd /dev/tcp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4194304</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>tcp_cwnd_max</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ndd/dev/tcp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2097152</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>tcp_xmit_hiwat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ndd /dev/tcp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8129</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">400000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">To increase the
transmit buffer.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>tcp_recv_hiwat</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ndd /dev/tcp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8129</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">400000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">To increase the receive
buffer.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Note that the IPGE driver version is 1.25.25.</p>
</div>
<div class="paragraph">
<p><a id="gfpzm"></a><a id="GSPTG00226"></a><a id="disk-configuration"></a></p>
</div>
</div>
<div class="sect3">
<h4 id="_disk_configuration">Disk Configuration</h4>
<div class="paragraph">
<p>If HTTP access is logged, follow these guidelines for the disk:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Write access logs on faster disks or attached storage.</p>
</li>
<li>
<p>If running multiple instances, move the logs for each instance onto
separate disks as much as possible.</p>
</li>
<li>
<p>Enable the disk read/write cache. Note that if you enable write cache
on the disk, some writes might be lost if the disk fails.</p>
</li>
<li>
<p>Consider mounting the disks with the following options, which might
yield better disk performance: <code>nologging</code>, <code>directio</code>, <code>noatime</code>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><a id="gfpzk"></a><a id="GSPTG00227"></a><a id="network-configuration"></a></p>
</div>
</div>
<div class="sect3">
<h4 id="_network_configuration">Network Configuration</h4>
<div class="paragraph">
<p>If more than one network interface card is used, make sure the network
interrupts are not all going to the same core. Run the following script
to disable interrupts:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">allpsr=`/usr/sbin/psrinfo | grep -v off-line | awk '{ print $1 }'`
   set $allpsr
   numpsr=$#
   while [ $numpsr -gt 0 ];
   do
       shift
       numpsr=`expr $numpsr - 1`
       tmp=1
       while [ $tmp -ne 4 ];
       do
           /usr/sbin/psradm -i $1
           shift
           numpsr=`expr $numpsr - 1`
           tmp=`expr $tmp + 1`
       done
   done</code></pre>
</div>
</div>
<div class="paragraph">
<p>Put all network interfaces into a single group. For example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight"><code class="language-oac_no_warn" data-lang="oac_no_warn">$ifconfig ipge0 group webserver
$ifconfig ipge1 group webserver</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>

<hr />

<table width="90%" id="bottom-nav" cellspacing="0" cellpadding="0">
	<colgroup>
		<col width="12%"/>
		<col width="12%"/>
		<col width="*"/>
	</colgroup>
	<tr>		
		<td align="left">
		<a href="tuning-java.html">
			<span class=" vector-font"><i class="fa fa-arrow-circle-left" aria-hidden="true"></i></span>
			<span style="position:relative;top:-2px;">Previous</span>
		</a>
		</td>


		<td align="right">
		<a href="toc.html">
			<span class="vector-font"><i class="fa fa-list vector-font" aria-hidden="true"></i></span>
			<span style="position:relative;top:-2px;">Contents</span>
		</a>
		</td>
	</tr>
</table>

<span id="copyright">
        <img src="/img/eclipse_foundation_logo_tiny.png" height="20px" alt="Eclipse Foundation Logo" align="top"/>&nbsp;            
        <span >Copyright&nbsp;&copy;&nbsp;2019,&nbsp;Oracle&nbsp;and/or&nbsp;its&nbsp;affiliates.&nbsp;All&nbsp;rights&nbsp;reserved.</span>
</span>
</body>
</html>